{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyt: 5.0.0-alpha.20200328\n",
      "pillow: 7.1.2\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd #\n",
    "import pytesseract #\n",
    "print('pyt:',pytesseract.get_tesseract_version())\n",
    "from PIL import Image #\n",
    "import PIL\n",
    "print('pillow:',PIL.__version__)\n",
    "# import cv2\n",
    "import numpy as np #\n",
    "# import os.path\n",
    "import urllib.request #urllib3\n",
    "from skimage.filters import  threshold_sauvola #\n",
    "filecounter = 0\n",
    "from skimage import data #\n",
    "from skimage.data import page #\n",
    "from skimage.filters import  threshold_sauvola #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.16.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('links_indexing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_links = links.loc[links['MN_year'] == '1850-51'] #subset dataframe with only 1850-51 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first set of links\n",
    " #getting all from links (from , to corresponds to the subset of links to be used from the scraped ones)\n",
    " #getting all to links\n",
    "from_url =year_links.iloc[0]['FROM_LINK']\n",
    "to_url = year_links.iloc[0]['TO_LINK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1\n",
    "#getting urls\n",
    "file = open('MN_scrapedlinks\\MN_1850-51.txt','r')\n",
    "Lines = file.read().splitlines()\n",
    "# print(Lines)\n",
    "subset_urls = []\n",
    "flag = False\n",
    "for item in Lines:\n",
    "    if(item == from_url):\n",
    "        flag = True\n",
    "    if(flag == True):\n",
    "        subset_urls.append(item)\n",
    "    if(item == to_url):\n",
    "        flag = False\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(urllib.request.urlopen('http://link.nypl.org/YaM1vgXiR9ivhW3dG5ai-wv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "#running on first one\n",
    "# from_ url = 'http://link.nypl.org/YaM1vgXiR9ivhW3dG5ai-wv' #-- start\n",
    "image = Image.open(urllib.request.urlopen(from_url))\n",
    "\n",
    "# cropping \n",
    "width, height = image.size   # Get dimensions\n",
    "left = width/4\n",
    "top =  height/5\n",
    "right = 4 * width/5\n",
    "bottom = 3.5 * height/5\n",
    "cropped_example = image.crop((left, top, right, bottom))\n",
    "\n",
    "#rotating\n",
    "rotated = cropped_example.transpose(Image.ROTATE_270)\n",
    "\n",
    "#local thresholding\n",
    "from skimage import data\n",
    "from skimage.data import page\n",
    "from skimage.filters import  threshold_sauvola\n",
    "\n",
    "grayimage = rotated.convert('L')\n",
    "f_image = np.asarray(grayimage)\n",
    "t_sauvola = threshold_sauvola(f_image, window_size=23)\n",
    "binary_image = f_image > t_sauvola\n",
    "print(type(binary_image))\n",
    "#saving binary image as a tif (required for obtaining hocr format from tesseract)\n",
    "new_im = Image.fromarray(binary_image)\n",
    "print(type(new_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import pytesseract\n",
    "new_im.save(\"saved.tif\")\n",
    "pytesseract.run_tesseract('saved.tif', 'output', lang=None, config=\"hocr\", extension=\"hocr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = !hocr-detect-columns --mode json output.hocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save json file\n",
    "filecounter += 1\n",
    "with open('tess_output/MN_1850-51/page{}.json'.format(filecounter), 'w',encoding=\"utf-8\") as f:\n",
    "    f.write(x.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tesseract Open Source OCR Engine v5.0.0-alpha.20200328 with Leptonica\n",
      "Page 1\n",
      "Warning: Invalid resolution 0 dpi. Using 70 instead.\n",
      "Estimating resolution as 295\n"
     ]
    }
   ],
   "source": [
    "#running on second type page\n",
    "# from_ url = 'http://link.nypl.org/YaM1vgXiR9ivhW3dG5ai-wv' #-- start\n",
    "image = Image.open(urllib.request.urlopen(to_url))\n",
    "\n",
    "# cropping \n",
    "width, height = image.size   # Get dimensions\n",
    "left = width/4\n",
    "top =  height/5\n",
    "right = 4 * width/5\n",
    "bottom = 3.5 * height/5\n",
    "cropped_example = image.crop((left, top, right, bottom))\n",
    "\n",
    "#rotating\n",
    "rotated = cropped_example.transpose(Image.ROTATE_90)\n",
    "\n",
    "#local thresholding\n",
    "\n",
    "\n",
    "grayimage = rotated.convert('L')\n",
    "f_image = np.asarray(grayimage)\n",
    "t_sauvola = threshold_sauvola(f_image, window_size=23)\n",
    "binary_image = f_image > t_sauvola\n",
    "#saving binary image as a tif (required for obtaining hocr format from tesseract)\n",
    "new_im = Image.fromarray(binary_image)\n",
    "#create hocr file\n",
    "new_im.save(\"saved.tif\")\n",
    "!tesseract \"saved.tif\" \"hocr_output\" -c tessedit_create_hocr=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = !hocr-detect-columns --mode json hocr_output.hocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save json file\n",
    "filecounter += 1\n",
    "with open('tess_output/MN_1850-51/page{}.json'.format(filecounter), 'w',encoding=\"utf-8\") as f:\n",
    "    f.write(x.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second set of links\n",
    "\n",
    "from_url =year_links.iloc[1]['FROM_LINK']\n",
    "to_url = year_links.iloc[1]['TO_LINK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1\n",
    "#getting urls\n",
    "file = open('MN_scrapedlinks\\MN_1850-51.txt','r')\n",
    "Lines = file.read().splitlines()\n",
    "# print(Lines)\n",
    "subset_urls = []\n",
    "flag = False\n",
    "for item in Lines:\n",
    "#         print(item)\n",
    "    if(item == from_url):\n",
    "    #             print('found')\n",
    "        flag = True\n",
    "    if(flag == True):\n",
    "        subset_urls.append(item)\n",
    "    if(item == to_url):\n",
    "#         subset_urls.append(item)\n",
    "        flag = False\n",
    "        break\n",
    "# subset_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filecounter = 2\n",
    "for i  in range(len(subset_urls)):\n",
    "    if(i % 2 == 0):\n",
    "\n",
    "        image = Image.open(urllib.request.urlopen(subset_urls[i]))\n",
    "        # display(image)\n",
    "\n",
    "        # cropping \n",
    "        width, height = image.size   # Get dimensions\n",
    "        left = width/4\n",
    "        top =  height/5\n",
    "        right = 4 * width/5\n",
    "        bottom = 3.5 * height/5\n",
    "        cropped_example = image.crop((left, top, right, bottom))\n",
    "        # display(cropped_example)\n",
    "\n",
    "        #rotating\n",
    "        rotated = cropped_example.transpose(Image.ROTATE_90)\n",
    "#         display(rotated)\n",
    "\n",
    "        #local thresholding\n",
    "\n",
    "        grayimage = rotated.convert('L')\n",
    "        f_image = np.asarray(grayimage)\n",
    "        t_sauvola = threshold_sauvola(f_image, window_size=23)\n",
    "        binary_image = f_image > t_sauvola\n",
    "        #saving binary image as a tif (required for obtaining hocr format from tesseract)\n",
    "        new_im = Image.fromarray(binary_image)\n",
    "        #create hocr file\n",
    "        new_im.save(\"saved.tif\")\n",
    "        !tesseract \"saved.tif\" \"hocr_output\" -c tessedit_create_hocr=1\n",
    "        x = !hocr-detect-columns --mode json hocr_output.hocr\n",
    "        #save json file\n",
    "        filecounter += 1\n",
    "        with open('tess_output/MN_1850-51/page{}.json'.format(filecounter), 'w',encoding=\"utf-8\") as f:\n",
    "            f.write(x.n)\n",
    "    else:\n",
    "        image = Image.open(urllib.request.urlopen(subset_urls[i]))\n",
    "        # display(image)\n",
    "\n",
    "        # cropping \n",
    "        width, height = image.size   # Get dimensions\n",
    "        left = width/4\n",
    "        top =  height/5\n",
    "        right = 4 * width/5\n",
    "        bottom = 3.5 * height/5\n",
    "        cropped_example = image.crop((left, top, right, bottom))\n",
    "        # display(cropped_example)\n",
    "\n",
    "        #rotating\n",
    "        rotated = cropped_example.transpose(Image.ROTATE_270)\n",
    "#         display(rotated)\n",
    "\n",
    "        #local thresholding\n",
    "\n",
    "        grayimage = rotated.convert('L')\n",
    "        f_image = np.asarray(grayimage)\n",
    "        t_sauvola = threshold_sauvola(f_image, window_size=23)\n",
    "        binary_image = f_image > t_sauvola\n",
    "        #saving binary image as a tif (required for obtaining hocr format from tesseract)\n",
    "        new_im = Image.fromarray(binary_image)\n",
    "        #create hocr file\n",
    "        new_im.save(\"saved.tif\")\n",
    "        !tesseract \"saved.tif\" \"hocr_output\" -c tessedit_create_hocr=1\n",
    "        x = !hocr-detect-columns --mode json hocr_output.hocr\n",
    "        #save json file\n",
    "        filecounter += 1\n",
    "        with open('tess_output/MN_1850-51/page{}.json'.format(filecounter), 'w',encoding=\"utf-8\") as f:\n",
    "            f.write(x.n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second set of links\n",
    "\n",
    "from_url =year_links.iloc[2]['FROM_LINK']\n",
    "to_url = year_links.iloc[2]['TO_LINK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting urls\n",
    "file = open('MN_scrapedlinks\\MN_1850-51.txt','r')\n",
    "Lines = file.read().splitlines()\n",
    "# print(Lines)\n",
    "subset_urls = []\n",
    "flag = False\n",
    "for item in Lines:\n",
    "#         print(item)\n",
    "    if(item == from_url):\n",
    "    #             print('found')\n",
    "        flag = True\n",
    "    if(flag == True):\n",
    "        subset_urls.append(item)\n",
    "    if(item == to_url):\n",
    "#         subset_urls.append(item)\n",
    "        flag = False\n",
    "        break\n",
    "# subset_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing\n",
    "# image = Image.open(urllib.request.urlopen(subset_urls[0]))\n",
    "# # display(image)\n",
    "\n",
    "# # cropping \n",
    "# width, height = image.size   # Get dimensions\n",
    "# left = width/4\n",
    "# top =  height/5\n",
    "# right = 4 * width/5\n",
    "# bottom = 3.5 * height/5\n",
    "# cropped_example = image.crop((left, top, right, bottom))\n",
    "# # display(cropped_example)\n",
    "\n",
    "# #rotating\n",
    "# rotated = cropped_example.transpose(Image.ROTATE_90)\n",
    "# display(rotated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecounter = 16\n",
    "for i  in range(len(subset_urls)):\n",
    "    if(i % 2 == 0):\n",
    "\n",
    "        image = Image.open(urllib.request.urlopen(subset_urls[i]))\n",
    "        # display(image)\n",
    "\n",
    "        # cropping \n",
    "        width, height = image.size   # Get dimensions\n",
    "        left = width/4\n",
    "        top =  height/5\n",
    "        right = 4 * width/5\n",
    "        bottom = 3.5 * height/5\n",
    "        cropped_example = image.crop((left, top, right, bottom))\n",
    "\n",
    "        #rotating\n",
    "        rotated = cropped_example.transpose(Image.ROTATE_90)\n",
    "\n",
    "        #local thresholding\n",
    "\n",
    "        grayimage = rotated.convert('L')\n",
    "        f_image = np.asarray(grayimage)\n",
    "        t_sauvola = threshold_sauvola(f_image, window_size=23)\n",
    "        binary_image = f_image > t_sauvola\n",
    "        #saving binary image as a tif (required for obtaining hocr format from tesseract)\n",
    "        new_im = Image.fromarray(binary_image)\n",
    "        #create hocr file\n",
    "        new_im.save(\"saved.tif\")\n",
    "        !tesseract \"saved.tif\" \"hocr_output\" -c tessedit_create_hocr=1\n",
    "        x = !hocr-detect-columns --mode json hocr_output.hocr\n",
    "        #save json file\n",
    "        filecounter += 1\n",
    "        with open('tess_output/MN_1850-51/page{}.json'.format(filecounter), 'w',encoding=\"utf-8\") as f:\n",
    "            f.write(x.n)\n",
    "    else:\n",
    "        image = Image.open(urllib.request.urlopen(subset_urls[i]))\n",
    "\n",
    "        # cropping \n",
    "        width, height = image.size   # Get dimensions\n",
    "        left = width/4\n",
    "        top =  height/5\n",
    "        right = 4 * width/5\n",
    "        bottom = 3.5 * height/5\n",
    "        cropped_example = image.crop((left, top, right, bottom))\n",
    "\n",
    "        #rotating\n",
    "        rotated = cropped_example.transpose(Image.ROTATE_270)\n",
    "\n",
    "        #local thresholding\n",
    "\n",
    "        grayimage = rotated.convert('L')\n",
    "        f_image = np.asarray(grayimage)\n",
    "        t_sauvola = threshold_sauvola(f_image, window_size=23)\n",
    "        binary_image = f_image > t_sauvola\n",
    "        #saving binary image as a tif (required for obtaining hocr format from tesseract)\n",
    "        new_im = Image.fromarray(binary_image)\n",
    "        #create hocr file\n",
    "        new_im.save(\"saved.tif\")\n",
    "        !tesseract \"saved.tif\" \"hocr_output\" -c tessedit_create_hocr=1\n",
    "        x = !hocr-detect-columns --mode json hocr_output.hocr\n",
    "        #save json file\n",
    "        filecounter += 1\n",
    "        with open('tess_output/MN_1850-51/page{}.json'.format(filecounter), 'w',encoding=\"utf-8\") as f:\n",
    "            f.write(x.n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hnyc",
   "language": "python",
   "name": "hnyc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
